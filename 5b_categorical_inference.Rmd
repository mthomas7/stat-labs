---
title: 'Lab 5B: Inference for categorical data and Margin of Error'
author: "Intro Stats"
date: "Fall 2018"
output:
  html_document:
    css: ./lab.css
    highlight: pygments
    theme: cerulean
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=T, results='hide', message=FALSE, warning=FALSE)
require(tidyverse)
require(moderndive)
atheism <- read_csv("atheism.csv")
```



## How does the proportion affect the margin of error?

Imagine you've set out to survey 1000 people on two questions: are you female? 
and are you left-handed? Since both of these sample proportions were 
calculated from the same sample size, they should have the same margin of 
error, right? Wrong! While the margin of error does change with sample size, 
it is also affected by the proportion.

Think back to the formula for the standard error: $SE = \sqrt{p(1-p)/n}$. This 
is then used in the formula for the margin of error for a 95% confidence 
interval: $ME = 1.96\times SE = 1.96\times\sqrt{p(1-p)/n}$. Since the 
population proportion $p$ is in this $ME$ formula, it should make sense that 
the margin of error is in some way dependent on the population proportion. We 
can visualize this relationship by creating a plot of $ME$ vs. $p$.

The first step is to make a vector `p` that is a sequence from 0 to 1 with 
each number separated by 0.01. We can then create a vector of the margin of 
error (`me`) associated with each of these values of `p` using the familiar 
approximate formula ($ME = 1.96 \times SE$). Lastly, we plot the two vectors 
against each other to reveal their relationship.

```{r eval=FALSE}
n <- 1000
p <- seq(0, 1, 0.01)
me <- 1.96 * sqrt(p * (1 - p)/n)

qplot(p,me)+labs(y = "Margin of Error", x = "Population Proportion")
```

8.  Describe the relationship between `p` and `me`.

## Success-failure condition

The textbook emphasizes that you must always check conditions before making 
inference. For inference on proportions, the sample proportion can be assumed 
to be nearly normal if it is based upon a random sample of independent 
observations and if both $np \geq 10$ and $n(1 - p) \geq 10$. This rule of 
thumb is easy enough to follow, but it makes one wonder: what's so special 
about the number 10?

The short answer is: nothing. You could argue that we would be fine with 9 or 
that we really should be using 11. What is the "best" value for such a rule of 
thumb is, at least to some degree, arbitrary. However, when $np$ and $n(1-p)$ 
reaches 10 the sampling distribution is sufficiently normal to use confidence 
intervals and hypothesis tests that are based on that approximation.

We can investigate the interplay between $n$ and $p$ and the shape of the 
sampling distribution by using simulations. To start off, we simulate the 
process of drawing 5000 samples of size 1040 from a population with a true 
atheist proportion of 0.1. For each of the 5000 samples we compute $\hat{p}$ 
and then plot a histogram to visualize their distribution.

```{r eval=FALSE}
p <- 0.1
n <- 1040

phat <- data.frame(atheist=c(1:20000))

for(i in 1:20000){
 phat[i,1] <- 
   summary(as.factor(sample(c("atheist","non_atheist"),n, replace=TRUE, prob = c(p, 1-p))))[1]/n
}

phat %>% 
  ggplot(aes(x=atheist))+
  geom_histogram()+
  labs(x = "p hat")
```

You can think of this chunk of code as "creating a sample of size $n$ with replacement from the choices of atheist and non-atheist with probabilities $p$ and $1 - p$, respectively." Then, it computes the proportion of each sample who are atheist, and does this entire process 20,000 times to build a good representation of the sampling distribution.

9.  Describe the sampling distribution of sample proportions at $n = 1040$ and 
    $p = 0.1$. Estimate (by eye) the center and spread and describe the shape. Note: you should change the number of bins to make sure you don't have any artifacts of the bin size. To do this, use something like `geom_histogram(bins=10)` or `geom_histogram(bins=40)`. Try a few.

10. Repeat the above simulation three more times but with modified sample sizes and proportions: for $n = 400$ and $p = 0.1$, $n = 1040$ and $p = 0.02$, and $n = 400$ and $p = 0.02$. Keep plots of all four histograms. Describe the three new sampling distributions. Based on these limited plots, how does $n$ appear to affect the distribution of $\hat{p}$? How does $p$ affect the sampling distribution?

11. If you refer to Table 6, you'll find that Australia has a sample 
    proportion of 0.1 on a sample size of 1040, and that Ecuador has a sample 
    proportion of 0.02 on 400 subjects. Let's suppose for this exercise that 
    these point estimates are actually the truth. Then given the shape of 
    their respective sampling distributions, do you think it is sensible to 
    proceed with inference and report margin of errors, as the reports does?

* * *

### On your own

-   Suppose you're hired by the local government to estimate the proportion of 
    residents that attend a religious service on a weekly basis. According to 
    the guidelines, the estimate must have a margin of error no greater than 
    1% with 95% confidence. You have no idea what to expect for $p$. How many 
    people would you have to sample to ensure that you are within the 
    guidelines?\
    *Hint:* Refer to your plot of the relationship between $p$ and margin of 
    error. Do not use the data set to answer this question.


<div id="license">
This is a product of OpenIntro that is released under a [Creative Commons 
Attribution-ShareAlike 3.0 Unported](http://creativecommons.org/licenses/by-sa/3.0). 
This lab was written for OpenIntro by Andrew Bray and Mine &Ccedil;etinkaya-Rundel. Modified by Ted Galanthay and Matt Thomas, November 2018.
</div>